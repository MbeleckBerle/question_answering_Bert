{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-22T03:06:56.317322Z",
     "start_time": "2023-01-22T03:06:55.620402Z"
    }
   },
   "outputs": [],
   "source": [
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning TFBertQuestionAnswering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-22T03:06:57.705692Z",
     "start_time": "2023-01-22T03:06:56.321164Z"
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-22T03:06:57.825111Z",
     "start_time": "2023-01-22T03:06:57.711395Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mojo/anaconda3/envs/tf2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-11-05 17:15:55.100627: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-05 17:15:55.253836: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1730844955.311926    2706 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1730844955.331188    2706 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-05 17:15:55.483927: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
    "from transformers import DefaultDataCollator\n",
    "from transformers import pipeline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### library versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets 3.0.2\n",
    "# pandas 2.2.3\n",
    "# transformers 4.46.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset\n",
    "### The dataset is a popular question-answering dataset called SQUAD. each datapoint consists of \n",
    "* A question\n",
    "* A context that may contain the answer to the question\n",
    "* The start  Index of the answer\n",
    "* The answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-22T03:33:54.265151Z",
     "start_time": "2023-01-22T03:33:53.915358Z"
    }
   },
   "outputs": [],
   "source": [
    "squad = load_dataset(\"squad\", split=\"train\")\n",
    "squad = squad.train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-22T03:33:55.281124Z",
     "start_time": "2023-01-22T03:33:55.144585Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id          False\n",
      "title       False\n",
      "context     False\n",
      "question    False\n",
      "answers     False\n",
      "dtype: bool\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>572826002ca10214002d9f12</td>\n",
       "      <td>Group_(mathematics)</td>\n",
       "      <td>Groups are also applied in many other mathemat...</td>\n",
       "      <td>What are usually analyzed by associating group...</td>\n",
       "      <td>{'text': ['Mathematical objects'], 'answer_sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5728140b4b864d19001643f4</td>\n",
       "      <td>George_VI</td>\n",
       "      <td>In February 1918, he was appointed Officer in ...</td>\n",
       "      <td>What position was Albert appointed at Cranwell?</td>\n",
       "      <td>{'text': ['Officer in Charge of Boys at the Ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57275893dd62a815002e9b6f</td>\n",
       "      <td>Cotton</td>\n",
       "      <td>Most cotton in the United States, Europe and A...</td>\n",
       "      <td>What is the cotton harvesting machine that rem...</td>\n",
       "      <td>{'text': ['cotton picker'], 'answer_start': [94]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>572670205951b619008f72a7</td>\n",
       "      <td>Dutch_language</td>\n",
       "      <td>In the United States, an almost extinct dialec...</td>\n",
       "      <td>What's the year that Jersey Dutch was last spo...</td>\n",
       "      <td>{'text': ['1921'], 'answer_start': [185]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56cf477faab44d1400b88f14</td>\n",
       "      <td>To_Kill_a_Mockingbird</td>\n",
       "      <td>In a 1964 interview, Lee remarked that her asp...</td>\n",
       "      <td>Who does the cooking at the Finch's house?</td>\n",
       "      <td>{'text': ['Calpurnia'], 'answer_start': [298]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id                  title  \\\n",
       "0  572826002ca10214002d9f12    Group_(mathematics)   \n",
       "1  5728140b4b864d19001643f4              George_VI   \n",
       "2  57275893dd62a815002e9b6f                 Cotton   \n",
       "3  572670205951b619008f72a7         Dutch_language   \n",
       "4  56cf477faab44d1400b88f14  To_Kill_a_Mockingbird   \n",
       "\n",
       "                                             context  \\\n",
       "0  Groups are also applied in many other mathemat...   \n",
       "1  In February 1918, he was appointed Officer in ...   \n",
       "2  Most cotton in the United States, Europe and A...   \n",
       "3  In the United States, an almost extinct dialec...   \n",
       "4  In a 1964 interview, Lee remarked that her asp...   \n",
       "\n",
       "                                            question  \\\n",
       "0  What are usually analyzed by associating group...   \n",
       "1    What position was Albert appointed at Cranwell?   \n",
       "2  What is the cotton harvesting machine that rem...   \n",
       "3  What's the year that Jersey Dutch was last spo...   \n",
       "4         Who does the cooking at the Finch's house?   \n",
       "\n",
       "                                             answers  \n",
       "0  {'text': ['Mathematical objects'], 'answer_sta...  \n",
       "1  {'text': ['Officer in Charge of Boys at the Ro...  \n",
       "2  {'text': ['cotton picker'], 'answer_start': [94]}  \n",
       "3          {'text': ['1921'], 'answer_start': [185]}  \n",
       "4     {'text': ['Calpurnia'], 'answer_start': [298]}  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the dataset to a dictionary\n",
    "data_dict = squad[\"train\"].to_dict()\n",
    "# Create a DataFrame from the dictionary\n",
    "df = pd.DataFrame.from_dict(data_dict)\n",
    "print(df.isna().any())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-22T03:33:56.165238Z",
     "start_time": "2023-01-22T03:33:55.601287Z"
    }
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-22T03:33:56.869103Z",
     "start_time": "2023-01-22T03:33:56.864148Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This function preprocesses tokenizes the data, adds the end position of the context to the data and returns the data and the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-22T03:33:57.669113Z",
     "start_time": "2023-01-22T03:33:57.443910Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def preprocess(df, type):\n",
    "\n",
    "    # remove whitespace and set maximum length of sentence\n",
    "    questions = [q.strip() for q in df[\"question\"]]\n",
    "    context = [q.strip() for q in df[\"context\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        context,\n",
    "        max_length=384,\n",
    "        truncation=\"only_second\",\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    start_positions = []\n",
    "    end_positions = []  # to store the end position of the context\n",
    "    answers = df[\"answers\"]\n",
    "\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        answer = answers[i]\n",
    "        start_char = answer[\"answer_start\"][0]\n",
    "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "        # Find the start and end of the context\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            \n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "\n",
    "        # If the answer is not fully inside the context, label it (0, 0)\n",
    "        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            # Otherwise it's the start and end token positions\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1)\n",
    "\n",
    "            idx = context_end\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1)\n",
    "\n",
    "    df[\"start_positions\"] = start_positions\n",
    "    df[\"end_positions\"] = end_positions\n",
    "\n",
    "    data = {\n",
    "        \"input_ids\": inputs[\"input_ids\"],\n",
    "        \"attention_mask\": inputs[\"attention_mask\"],\n",
    "        \"start_positions\": start_positions,\n",
    "        \"end_positions\": end_positions,\n",
    "    }\n",
    "    type = f\"encoding_{type}\"\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(f\"{type}.csv\", index=False)\n",
    "    data = {\n",
    "        \"input_ids\": inputs[\"input_ids\"],\n",
    "        \"attention_mask\": inputs[\"attention_mask\"],\n",
    "        \"start_positions\": start_positions,\n",
    "        \"end_positions\": end_positions,\n",
    "    }\n",
    "    data = Dataset.from_pandas(df)\n",
    "    return df, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-22T04:16:05.785112Z",
     "start_time": "2023-01-22T04:16:05.548343Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
      "    num_rows: 70079\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>start_positions</th>\n",
       "      <th>end_positions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[101, 2054, 2024, 2788, 16578, 2011, 4632, 100...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>32</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[101, 2054, 2597, 2001, 4789, 2805, 2012, 1367...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>19</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[101, 2054, 2003, 1996, 6557, 21534, 3698, 200...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>35</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[101, 2054, 1005, 1055, 1996, 2095, 2008, 3933...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[101, 2040, 2515, 1996, 8434, 2012, 1996, 1613...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>76</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           input_ids  \\\n",
       "0  [101, 2054, 2024, 2788, 16578, 2011, 4632, 100...   \n",
       "1  [101, 2054, 2597, 2001, 4789, 2805, 2012, 1367...   \n",
       "2  [101, 2054, 2003, 1996, 6557, 21534, 3698, 200...   \n",
       "3  [101, 2054, 1005, 1055, 1996, 2095, 2008, 3933...   \n",
       "4  [101, 2040, 2515, 1996, 8434, 2012, 1996, 1613...   \n",
       "\n",
       "                                      attention_mask  start_positions  \\\n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...               32   \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...               19   \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...               35   \n",
       "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...               56   \n",
       "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...               76   \n",
       "\n",
       "   end_positions  \n",
       "0             33  \n",
       "1             29  \n",
       "2             37  \n",
       "3             56  \n",
       "4             78  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, train = preprocess(df, \"train\")\n",
    "print(train)\n",
    "_.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pre-processing the Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-22T04:16:48.893326Z",
     "start_time": "2023-01-22T04:16:48.818540Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert the dataset to a dictionary\n",
    "data_dict = squad[\"test\"].to_dict()\n",
    "# Create a DataFrame from the dictionary\n",
    "df = pd.DataFrame.from_dict(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['input_ids', 'attention_mask', 'start_positions', 'end_positions'],\n",
      "    num_rows: 17520\n",
      "})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>start_positions</th>\n",
       "      <th>end_positions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[101, 2043, 2001, 1996, 2645, 1997, 23136, 406...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[101, 15053, 1011, 13838, 2764, 3365, 16105, 9...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>73</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[101, 2065, 4957, 2003, 2025, 3048, 1010, 2073...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>113</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[101, 2054, 2095, 2001, 1996, 2034, 3444, 2143...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>96</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[101, 2129, 2116, 3645, 1022, 15943, 2020, 415...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>85</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           input_ids  \\\n",
       "0  [101, 2043, 2001, 1996, 2645, 1997, 23136, 406...   \n",
       "1  [101, 15053, 1011, 13838, 2764, 3365, 16105, 9...   \n",
       "2  [101, 2065, 4957, 2003, 2025, 3048, 1010, 2073...   \n",
       "3  [101, 2054, 2095, 2001, 1996, 2034, 3444, 2143...   \n",
       "4  [101, 2129, 2116, 3645, 1022, 15943, 2020, 415...   \n",
       "\n",
       "                                      attention_mask  start_positions  \\\n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...               62   \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...               73   \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...              113   \n",
       "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...               96   \n",
       "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...               85   \n",
       "\n",
       "   end_positions  \n",
       "0             62  \n",
       "1             74  \n",
       "2            115  \n",
       "3             96  \n",
       "4             86  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, test = preprocess(df, \"test\")\n",
    "print(test)\n",
    "_.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning BERT for the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-22T04:17:29.037138Z",
     "start_time": "2023-01-22T04:17:27.631538Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/mojo/anaconda3/envs/tf2/lib/python3.10/site-packages/transformers/training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForQuestionAnswering.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "data_collator = DefaultDataCollator()\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"question_answering_model\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-22T04:19:10.789151Z",
     "start_time": "2023-01-22T04:17:39.064087Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_33984/1516768899.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13140' max='13140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13140/13140 57:59, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.273700</td>\n",
       "      <td>1.164262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.965000</td>\n",
       "      <td>1.089928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.789900</td>\n",
       "      <td>1.115258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=13140, training_loss=1.1296380308665097, metrics={'train_runtime': 3481.4314, 'train_samples_per_second': 60.388, 'train_steps_per_second': 3.774, 'total_flos': 2.060108684357069e+16, 'train_loss': 1.1296380308665097, 'epoch': 3.0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training for 5 epochs\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train,\n",
    "    eval_dataset=test,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.8985372185707092, 'start': 93, 'end': 95, 'answer': '13'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"How many programming languages does BLOOM support?\"\n",
    "context = \"BLOOM has 176 billion parameters and can generate text in 46 languages natural languages and 13 programming languages.\"\n",
    "\n",
    "\n",
    "question_answerer = pipeline(\n",
    "    \"question-answering\", model=\"./question_answering_model/checkpoint-21900\"\n",
    ")\n",
    "question_answerer(question=question, context=context)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
